{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "presidential-spelling",
   "metadata": {},
   "source": [
    "## data prep for automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incredible-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spread-float",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('thyroid_ltd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hawaiian-monte",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(652, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "designing-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    dirname = 'single' if row['target'] == '1' else 'multiple'\n",
    "    filename = \"data/dataset/\"+ dirname + '/example_' + str(idx)+\".txt\"\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, \"w+\") as f:\n",
    "        f.write(row['Exam Result'])\n",
    "    f.close()\n",
    "\n",
    "    #print (idx)\n",
    "    #print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-right",
   "metadata": {},
   "source": [
    "## predict using automl model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "contemporary-asbestos",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class name: single\n",
      "Predicted class score: 0.9907870888710022\n",
      "Predicted class name: multiple\n",
      "Predicted class score: 0.009212881326675415\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import automl\n",
    "\n",
    "# TODO(developer): Uncomment and set the following variables\n",
    "project_id = '666716883415'\n",
    "model_id = 'TCN2248943282476285952'\n",
    "\n",
    "\n",
    "#below is a sample for a test report...\n",
    "content = test['Exam Result'].iloc[0]\n",
    "\n",
    "prediction_client = automl.PredictionServiceClient()\n",
    "\n",
    "# Get the full path of the model.\n",
    "model_full_id = automl.AutoMlClient.model_path(project_id, \"us-central1\", model_id)\n",
    "\n",
    "# Supported mime_types: 'text/plain', 'text/html'\n",
    "# https://cloud.google.com/automl/docs/reference/rpc/google.cloud.automl.v1#textsnippet\n",
    "text_snippet = automl.TextSnippet(content=content, mime_type=\"text/plain\")\n",
    "payload = automl.ExamplePayload(text_snippet=text_snippet)\n",
    "\n",
    "response = prediction_client.predict(name=model_full_id, payload=payload)\n",
    "\n",
    "for annotation_payload in response.payload:\n",
    "    print(u\"Predicted class name: {}\".format(annotation_payload.display_name))\n",
    "    print(\n",
    "        u\"Predicted class score: {}\".format(annotation_payload.classification.score)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-singing",
   "metadata": {},
   "source": [
    "This is the loop through all the reports in the test set and making a list of all the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "prescription-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "for rep in test['Exam Result']:\n",
    "    text_snippet = automl.TextSnippet(content=rep, mime_type=\"text/plain\")\n",
    "    payload = automl.ExamplePayload(text_snippet=text_snippet)\n",
    "    response = prediction_client.predict(name=model_full_id, payload=payload)\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "whole-certification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "radio-administration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "payload {\n",
       "  annotation_spec_id: \"6973062061425164288\"\n",
       "  classification {\n",
       "    score: 0.9907871\n",
       "  }\n",
       "  display_name: \"single\"\n",
       "}\n",
       "payload {\n",
       "  annotation_spec_id: \"1208454538390929408\"\n",
       "  classification {\n",
       "    score: 0.009212881\n",
       "  }\n",
       "  display_name: \"multiple\"\n",
       "}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just have a look at the format of a single reponse\n",
    "responses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "comfortable-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty dataframe\n",
    "results_df = pd.DataFrame(columns = ['single', 'multiple'], index = range(len(responses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "scenic-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through the responses and populate the dataframe appropriately\n",
    "for i, res in enumerate(responses):\n",
    "    for payload in res.payload:\n",
    "        results_df.iloc[i][payload.display_name] = payload.classification.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "unlike-absolute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>single</th>\n",
       "      <th>multiple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.990787</td>\n",
       "      <td>0.009213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.990224</td>\n",
       "      <td>0.009776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.996347</td>\n",
       "      <td>0.003653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.450748</td>\n",
       "      <td>0.549252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.997189</td>\n",
       "      <td>0.002812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     single  multiple\n",
       "0  0.990787  0.009213\n",
       "1  0.990224  0.009776\n",
       "2  0.996347  0.003653\n",
       "3  0.450748  0.549252\n",
       "4  0.997189  0.002812"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "connected-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "animated-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(df, thresh = 0.5):\n",
    "    preds = np.array([df.single, df.multiple])\n",
    "    prediction = 0 if preds[0] >= thresh else 1\n",
    "    return '1' if prediction == 0 else '>1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "abstract-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['predictions_0.5'] = results_df.apply(get_predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "annoying-tuesday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>single</th>\n",
       "      <th>multiple</th>\n",
       "      <th>predictions_0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.990787</td>\n",
       "      <td>0.009213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.990224</td>\n",
       "      <td>0.009776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.996347</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.450748</td>\n",
       "      <td>0.549252</td>\n",
       "      <td>&gt;1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.997189</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     single  multiple predictions_0.5\n",
       "0  0.990787  0.009213               1\n",
       "1  0.990224  0.009776               1\n",
       "2  0.996347  0.003653               1\n",
       "3  0.450748  0.549252              >1\n",
       "4  0.997189  0.002812               1"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "simplified-repair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'1': 44, '>1': 4})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(results_df['predictions_0.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "superior-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "vietnamese-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "get_pred = partial(get_predictions, thresh = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "separated-record",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function get_predictions at 0x000001633549BDC0>, thresh=0.6)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "smart-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "for thresh in thresholds:\n",
    "    col_name = 'predictions_' + str(thresh)\n",
    "    get_pred = partial(get_predictions,thresh = thresh)\n",
    "    results_df[col_name] = results_df.apply(get_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ethical-skating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>single</th>\n",
       "      <th>multiple</th>\n",
       "      <th>predictions_0.5</th>\n",
       "      <th>predictions_0.55</th>\n",
       "      <th>predictions_0.6</th>\n",
       "      <th>predictions_0.65</th>\n",
       "      <th>predictions_0.7</th>\n",
       "      <th>predictions_0.75</th>\n",
       "      <th>predictions_0.8</th>\n",
       "      <th>predictions_0.85</th>\n",
       "      <th>predictions_0.9</th>\n",
       "      <th>predictions_0.95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.990787</td>\n",
       "      <td>0.009213</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.990224</td>\n",
       "      <td>0.009776</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.996347</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.450748</td>\n",
       "      <td>0.549252</td>\n",
       "      <td>&gt;1</td>\n",
       "      <td>&gt;1</td>\n",
       "      <td>&gt;1</td>\n",
       "      <td>&gt;1</td>\n",
       "      <td>&gt;1</td>\n",
       "      <td>&gt;1</td>\n",
       "      <td>&gt;1</td>\n",
       "      <td>&gt;1</td>\n",
       "      <td>&gt;1</td>\n",
       "      <td>&gt;1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.997189</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     single  multiple predictions_0.5 predictions_0.55 predictions_0.6  \\\n",
       "0  0.990787  0.009213               1                1               1   \n",
       "1  0.990224  0.009776               1                1               1   \n",
       "2  0.996347  0.003653               1                1               1   \n",
       "3  0.450748  0.549252              >1               >1              >1   \n",
       "4  0.997189  0.002812               1                1               1   \n",
       "\n",
       "  predictions_0.65 predictions_0.7 predictions_0.75 predictions_0.8  \\\n",
       "0                1               1                1               1   \n",
       "1                1               1                1               1   \n",
       "2                1               1                1               1   \n",
       "3               >1              >1               >1              >1   \n",
       "4                1               1                1               1   \n",
       "\n",
       "  predictions_0.85 predictions_0.9 predictions_0.95  \n",
       "0                1               1                1  \n",
       "1                1               1                1  \n",
       "2                1               1                1  \n",
       "3               >1              >1               >1  \n",
       "4                1               1                1  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "urban-creator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'1': 44, '>1': 4})\n",
      "Counter({'1': 43, '>1': 5})\n",
      "Counter({'1': 43, '>1': 5})\n",
      "Counter({'1': 43, '>1': 5})\n",
      "Counter({'1': 43, '>1': 5})\n",
      "Counter({'1': 43, '>1': 5})\n",
      "Counter({'1': 43, '>1': 5})\n",
      "Counter({'1': 42, '>1': 6})\n",
      "Counter({'1': 41, '>1': 7})\n",
      "Counter({'1': 37, '>1': 11})\n"
     ]
    }
   ],
   "source": [
    "for col in list(results_df.columns)[2:]:\n",
    "    print (Counter(results_df[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "phantom-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('test_predictions.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
